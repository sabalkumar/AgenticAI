{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MzCbwRyBKdi"
      },
      "source": [
        "## Welcome to Lab 3 for Week 1 Day 4\n",
        "\n",
        "Today we're going to build something with immediate value!\n",
        "\n",
        "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
        "\n",
        "Please replace it with yours!\n",
        "\n",
        "I've also made a file called `summary.txt`\n",
        "\n",
        "We're not going to use Tools just yet - we're going to add the tool tomorrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mZVNd6nBKdk"
      },
      "source": [
        "<table style=\"margin: 0; text-align: left; width:100%\">\n",
        "    <tr>\n",
        "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
        "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
        "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs,\n",
        "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking\n",
        "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
        "            </span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Z3F_7mqBKdk"
      },
      "outputs": [],
      "source": [
        "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from pypdf import PdfReader\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YOGNqahvBKdl"
      },
      "outputs": [],
      "source": [
        "load_dotenv(override=True)\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqi95411CMV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = PdfReader(\"/content/me/Sanjay.pdf\")\n",
        "linkedin = \"\"\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        linkedin += text"
      ],
      "metadata": {
        "id": "7yBrVUmtBqo2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y-xO6c1nBKdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b02d2ff-17ca-49ab-da8c-e6048f72ea42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Contact\n",
            "sanjayfuloria@gmail.com\n",
            "www.linkedin.com/in/sanjayfuloria\n",
            "(LinkedIn)\n",
            "Top Skills\n",
            "Unsupervised Learning\n",
            "Applied Machine Learning\n",
            "Linear Algebra\n",
            "Certifications\n",
            "Mathematics for Machine Learning\n",
            "Programming for Everybody (Getting\n",
            "Started with Python)\n",
            "Capstone: Retrieving, Processing,\n",
            "and Visualizing Data with Python\n",
            "Machine Learning\n",
            "Machine Learning Specialization\n",
            "Sanjay Fuloria Ph.D.\n",
            "Professor and Director Center for Distance and Online Education,\n",
            "ICFAI FOUNDATION FOR HIGHER EDUCATION (a deemed to\n",
            "be University under Section 3 of the UGC Act) , Hyderabad at IBS\n",
            "Hyderabad\n",
            "Hyderabad, Telangana, India\n",
            "Summary\n",
            "I have 26 years of experience in both academics and the corporate\n",
            "world. I have handled marketing and sales, taught market research,\n",
            "analytics and practiced business research, team management and\n",
            "application of various analytics and machine learning tools and\n",
            "techniques.\n",
            "Experience\n",
            "IBS Hyderabad\n",
            "6 years 3 months\n",
            "Professor and Director, Center for Distance and Online Education\n",
            "(CDOE), IFHE University, Hyderabad\n",
            "June 2021 - Present (4 years 3 months)\n",
            "Hyderabad, Telangana, India\n",
            "I am handling online distance education (ODL) and online education programs\n",
            "of ICFAI Foundation for Higher Education (IFHE) University, Hyderabad.\n",
            "This involves program design, curriculum design, online lectures, and other\n",
            "coordination activities.\n",
            "Professor\n",
            "June 2019 - Present (6 years 3 months)\n",
            "Hyderabad Area, India\n",
            "Teaching Advanced Analytics, Business Research Methods, Project\n",
            "Management and other analytical subjects.\n",
            "Cognizant Technology Solutions\n",
            "8 years 5 months\n",
            "General Manager\n",
            "June 2015 - June 2019 (4 years 1 month)\n",
            "Hyderabad Area, India\n",
            "  Page 1 of 2   \n",
            "Handled Research as a Service division of Cognizant as part of the Cognizant\n",
            "Research Center. Was managing research teams. Worked on research\n",
            "and analytics projects for various internationally renowned Fortune 500\n",
            "Companies. Was instrumental in hiring, training, managing, and counselling\n",
            "people.\n",
            "Deputy General Manager\n",
            "February 2011 - June 2015 (4 years 5 months)\n",
            "Hyderabad Area, India\n",
            "Worked on Principal Component Analysis based models. Have hands on\n",
            "experience in using techniques like Conjoint Analysis, RFM models, Customer\n",
            "Life Time Value and Survival Analysis.\n",
            "Education\n",
            "Indian School of Business\n",
            "Executive Education Leadership with AI, Business, Management, Marketing,\n",
            "and Related Support Services · (February 2024 - July 2024)\n",
            "ICFAI Foundation for Higher Education, Hyderabad\n",
            "Doctor of Philosophy - PhD, PhD in Management, Technology and\n",
            "Strategy · (2002 - 2007)\n",
            "Malviya National Institute of Technology, Jaipur\n",
            "Master of Management Studies, MMS, Management- Marketing and\n",
            "IT · (1997 - 1999)\n",
            "Bhilai Institute of Technology (BIT), Durg\n",
            "Bachelor of Engineering - BE (Electronics & Communications), Electronics &\n",
            "Communications · (1992 - 1996)\n",
            "  Page 2 of 2\n"
          ]
        }
      ],
      "source": [
        "print(linkedin)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    summary = f.read()"
      ],
      "metadata": {
        "id": "IOLppFpbOTQs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AL7rp4tFBKdm"
      },
      "outputs": [],
      "source": [
        "name = \"Sanjay Fuloria\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "31Ryq-EABKdm"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
        "particularly questions related to {name}'s career, background, skills and experience. \\\n",
        "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
        "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
        "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
        "If you don't know the answer, say so.\"\n",
        "\n",
        "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
        "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L5rRQnIwBKdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0f60cb55-ff26-4d4f-af18-142fd49d6abf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are acting as Sanjay Fuloria. You are answering questions on Sanjay Fuloria's website, particularly questions related to Sanjay Fuloria's career, background, skills and experience. Your responsibility is to represent Sanjay Fuloria for interactions on the website as faithfully as possible. You are given a summary of Sanjay Fuloria's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nContact\\nsanjayfuloria@gmail.com\\nwww.linkedin.com/in/sanjayfuloria\\n(LinkedIn)\\nTop Skills\\nUnsupervised Learning\\nApplied Machine Learning\\nLinear Algebra\\nCertifications\\nMathematics for Machine Learning\\nProgramming for Everybody (Getting\\nStarted with Python)\\nCapstone: Retrieving, Processing,\\nand Visualizing Data with Python\\nMachine Learning\\nMachine Learning Specialization\\nSanjay Fuloria Ph.D.\\nProfessor and Director Center for Distance and Online Education,\\nICFAI FOUNDATION FOR HIGHER EDUCATION (a deemed to\\nbe University under Section 3 of the UGC Act) , Hyderabad at IBS\\nHyderabad\\nHyderabad, Telangana, India\\nSummary\\nI have 26 years of experience in both academics and the corporate\\nworld. I have handled marketing and sales, taught market research,\\nanalytics and practiced business research, team management and\\napplication of various analytics and machine learning tools and\\ntechniques.\\nExperience\\nIBS Hyderabad\\n6 years 3 months\\nProfessor and Director, Center for Distance and Online Education\\n(CDOE), IFHE University, Hyderabad\\nJune 2021 - Present (4 years 3 months)\\nHyderabad, Telangana, India\\nI am handling online distance education (ODL) and online education programs\\nof ICFAI Foundation for Higher Education (IFHE) University, Hyderabad.\\nThis involves program design, curriculum design, online lectures, and other\\ncoordination activities.\\nProfessor\\nJune 2019 - Present (6 years 3 months)\\nHyderabad Area, India\\nTeaching Advanced Analytics, Business Research Methods, Project\\nManagement and other analytical subjects.\\nCognizant Technology Solutions\\n8 years 5 months\\nGeneral Manager\\nJune 2015 - June 2019 (4 years 1 month)\\nHyderabad Area, India\\n  Page 1 of 2   \\nHandled Research as a Service division of Cognizant as part of the Cognizant\\nResearch Center. Was managing research teams. Worked on research\\nand analytics projects for various internationally renowned Fortune 500\\nCompanies. Was instrumental in hiring, training, managing, and counselling\\npeople.\\nDeputy General Manager\\nFebruary 2011 - June 2015 (4 years 5 months)\\nHyderabad Area, India\\nWorked on Principal Component Analysis based models. Have hands on\\nexperience in using techniques like Conjoint Analysis, RFM models, Customer\\nLife Time Value and Survival Analysis.\\nEducation\\nIndian School of Business\\nExecutive Education Leadership with AI, Business, Management, Marketing,\\nand Related Support Services · (February 2024 - July 2024)\\nICFAI Foundation for Higher Education, Hyderabad\\nDoctor of Philosophy - PhD, PhD in Management, Technology and\\nStrategy · (2002 - 2007)\\nMalviya National Institute of Technology, Jaipur\\nMaster of Management Studies, MMS, Management- Marketing and\\nIT · (1997 - 1999)\\nBhilai Institute of Technology (BIT), Durg\\nBachelor of Engineering - BE (Electronics & Communications), Electronics &\\nCommunications · (1992 - 1996)\\n  Page 2 of 2\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nsanjayfuloria@gmail.com\\nwww.linkedin.com/in/sanjayfuloria\\n(LinkedIn)\\nTop Skills\\nUnsupervised Learning\\nApplied Machine Learning\\nLinear Algebra\\nCertifications\\nMathematics for Machine Learning\\nProgramming for Everybody (Getting\\nStarted with Python)\\nCapstone: Retrieving, Processing,\\nand Visualizing Data with Python\\nMachine Learning\\nMachine Learning Specialization\\nSanjay Fuloria Ph.D.\\nProfessor and Director Center for Distance and Online Education,\\nICFAI FOUNDATION FOR HIGHER EDUCATION (a deemed to\\nbe University under Section 3 of the UGC Act) , Hyderabad at IBS\\nHyderabad\\nHyderabad, Telangana, India\\nSummary\\nI have 26 years of experience in both academics and the corporate\\nworld. I have handled marketing and sales, taught market research,\\nanalytics and practiced business research, team management and\\napplication of various analytics and machine learning tools and\\ntechniques.\\nExperience\\nIBS Hyderabad\\n6 years 3 months\\nProfessor and Director, Center for Distance and Online Education\\n(CDOE), IFHE University, Hyderabad\\nJune 2021\\xa0-\\xa0Present\\xa0(4 years 3 months)\\nHyderabad, Telangana, India\\nI am handling online distance education (ODL) and online education programs\\nof ICFAI Foundation for Higher Education (IFHE) University, Hyderabad.\\nThis involves program design, curriculum design, online lectures, and other\\ncoordination activities.\\nProfessor\\nJune 2019\\xa0-\\xa0Present\\xa0(6 years 3 months)\\nHyderabad Area, India\\nTeaching Advanced Analytics, Business Research Methods, Project\\nManagement and other analytical subjects.\\nCognizant Technology Solutions\\n8 years 5 months\\nGeneral Manager\\nJune 2015\\xa0-\\xa0June 2019\\xa0(4 years 1 month)\\nHyderabad Area, India\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nHandled Research as a Service division of Cognizant as part of the Cognizant\\nResearch Center. Was managing research teams. Worked on research\\nand analytics projects for various internationally renowned Fortune 500\\nCompanies. Was instrumental in hiring, training, managing, and counselling\\npeople.\\nDeputy General Manager\\nFebruary 2011\\xa0-\\xa0June 2015\\xa0(4 years 5 months)\\nHyderabad Area, India\\nWorked on Principal Component Analysis based models. Have hands on\\nexperience in using techniques like Conjoint Analysis, RFM models, Customer\\nLife Time Value and Survival Analysis.\\nEducation\\nIndian School of Business\\nExecutive Education Leadership with AI,\\xa0Business, Management, Marketing,\\nand Related Support Services\\xa0·\\xa0(February 2024\\xa0-\\xa0July 2024)\\nICFAI Foundation for Higher Education, Hyderabad\\nDoctor of Philosophy - PhD,\\xa0PhD in Management, Technology and\\nStrategy\\xa0·\\xa0(2002\\xa0-\\xa02007)\\nMalviya National Institute of Technology, Jaipur\\nMaster of Management Studies, MMS,\\xa0Management- Marketing and\\nIT\\xa0·\\xa0(1997\\xa0-\\xa01999)\\nBhilai Institute of Technology (BIT), Durg\\nBachelor of Engineering - BE (Electronics & Communications),\\xa0Electronics &\\nCommunications\\xa0·\\xa0(1992\\xa0-\\xa01996)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Sanjay Fuloria.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "system_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZKOqo6TxBKdm"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWCfq8fBBKdm"
      },
      "source": [
        "## Special note for people not using OpenAI\n",
        "\n",
        "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
        "\n",
        "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
        "\n",
        "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
        "\n",
        "```python\n",
        "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
        "```\n",
        "\n",
        "You may need to add this in other chat() callback functions in the future, too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vm27KPsnBKdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "30308a6b-9d34-4d7f-d0b8-d9906b90b094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7e9c5709bea0f169ee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7e9c5709bea0f169ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nLvZffTBKdn"
      },
      "source": [
        "## A lot is about to happen...\n",
        "\n",
        "1. Be able to ask an LLM to evaluate an answer\n",
        "2. Be able to rerun if the answer fails evaluation\n",
        "3. Put this together into 1 workflow\n",
        "\n",
        "All without any Agentic framework!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OHRUzdaKBKdn"
      },
      "outputs": [],
      "source": [
        "# Create a Pydantic model for the Evaluation\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gk_TTXpHBKdn"
      },
      "outputs": [],
      "source": [
        "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
        "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
        "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
        "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
        "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
        "\n",
        "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
        "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "R_rhWaHGBKdn"
      },
      "outputs": [],
      "source": [
        "def evaluator_user_prompt(reply, message, history):\n",
        "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
        "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
        "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
        "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jvDWZHwMBKdn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# The base_url should point to the OpenAI API endpoint\n",
        "chatgpt = OpenAI(\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    base_url=\"https://api.openai.com/v1\" # Corrected base_url\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Dil8XgEaBKdn"
      },
      "outputs": [],
      "source": [
        "def evaluate(reply, message, history) -> Evaluation:\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
        "    response = openai.chat.completions.parse(model=\"gpt-4o-mini\", messages=messages, response_format=Evaluation)\n",
        "    return response.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FTN6FcngBKdn"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
        "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "reply = response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "csCkUADgBKdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a1dc6ccf-76c5-4581-e18f-9ad1fe28efce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not hold any patents. My expertise primarily lies in academia and corporate research, focusing on analytics and machine learning. If you have any questions about my work or experience in those areas, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6UtpzQAfBKdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8df56ff-1548-4e67-a6c9-bbd8d85a26cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(is_acceptable=True, feedback=\"The response is clear and directly answers the user's question about holding a patent. It also maintains a professional tone and invites further questions regarding the Agent's expertise, which is in line with the role of representing Sanjay Fuloria. Overall, the response is acceptable quality.\")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "evaluate(reply, \"do you hold a patent?\", messages[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ui7TbSDqBKdo"
      },
      "outputs": [],
      "source": [
        "def rerun(reply, message, history, feedback):\n",
        "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
        "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
        "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
        "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VBD5SKCpBKdo"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    if \"patent\" in message:\n",
        "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
        "              it is mandatory that you respond only and entirely in pig latin\"\n",
        "    else:\n",
        "        system = system_prompt\n",
        "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    reply =response.choices[0].message.content\n",
        "\n",
        "    evaluation = evaluate(reply, message, history)\n",
        "\n",
        "    if evaluation.is_acceptable:\n",
        "        print(\"Passed evaluation - returning reply\")\n",
        "    else:\n",
        "        print(\"Failed evaluation - retrying\")\n",
        "        print(evaluation.feedback)\n",
        "        reply = rerun(reply, message, history, evaluation.feedback)\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nxTMhrOJBKdo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "33058745-d8a2-42e2-db9e-2c37c66b137e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e7a1a8cd39232eff24.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7a1a8cd39232eff24.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxsVeHsmBKdo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9722ba3b",
        "outputId": "4332081c-ff95-4b85-bb70-353bc98401e1"
      },
      "source": [
        "%pip install python-dotenv openai pypdf gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, pypdf\n",
            "Successfully installed pypdf-5.9.0 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e98cfcc",
        "outputId": "b8ced7e8-4250-4746-cde3-1d71d23e97bb"
      },
      "source": [
        "%%writefile /content/.env\n",
        "OPENAI_API_KEY = Your OpenAI API key\n",
        "ANTHROPIC_API_KEY = Your Anthropic API key\n",
        "GROQ_API_KEY = Your Groq API key"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ad39c19"
      },
      "source": [
        "!mkdir /content/me"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}